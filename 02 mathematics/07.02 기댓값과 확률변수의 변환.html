

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>7.2 기댓값과 확률변수의 변환 &#8212; 데이터 사이언스 스쿨</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "datascienceschool/book");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7.3 분산과 표준편차" href="07.03 분산과 표준편차.html" />
    <link rel="prev" title="7.1 확률적 데이터와 확률변수" href="07.01 확률적 데이터와 확률변수.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.svg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">데이터 사이언스 스쿨</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   데이터 사이언스 스쿨
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  파이썬 편
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../01 python/00.00 소개의 글.html">
   소개의 글
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01 python/01.00 1장 파이썬 설치와 설정.html">
   1장 파이썬 설치와 설정
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01 python/02.00 2장 파이썬 기초 문법.html">
   2장 파이썬 기초문법
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01 python/03.00 3장 넘파이 배열 프로그래밍.html">
   3장 넘파이 배열 프로그래밍
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01 python/04.00 4장 판다스 데이터 분석.html">
   4장 판다스 데이터 분석
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01 python/05.00 5장 데이터 시각화.html">
   5장 데이터 시각화
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  수학 편
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="00.00 소개의 글.html">
   소개의 글
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="01.00 1장 수학 기호.html">
   1장 수학 기호
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02.00 2장 넘파이(NumPy)로 공부하는 선형대수.html">
   2장 넘파이(NumPy)로 공부하는 선형대수
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03.00 3장 고급 선형대수.html">
   3장 고급 선형대수
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04.00 4장 심파이(SymPy)로 공부하는 미적분.html">
   4장 심파이(SymPy)로 공부하는 미적분
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05.00 5장 사이파이(SciPy)로 공부하는 최적화.html">
   5장 사이파이(SciPy)로 공부하는 최적화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06.00 6장 피지엠파이(pgmpy)로 공부하는 확률론.html">
   6장 피지엠파이(pgmpy)로 공부하는 확률론
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="07.00 7장 확률변수와 상관관계.html">
   7장 확률변수와 상관관계
  </a>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="07.01 확률적 데이터와 확률변수.html">
     7.1 확률적 데이터와 확률변수
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     7.2 기댓값과 확률변수의 변환
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.03 분산과 표준편차.html">
     7.3 분산과 표준편차
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.04 다변수 확률변수.html">
     7.4 다변수 확률변수
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.05 공분산과 상관계수.html">
     7.5 공분산과 상관계수
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.06 조건부기댓값과 예측 문제.html">
     7.6 조건부기댓값과 예측 문제
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08.00 8장 사이파이로 공부하는 확률분포.html">
   8장 사이파이로 공부하는 확률분포
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09.00 9장 추정과 검정.html">
   9장 추정과 검정
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10.00 10장 엔트로피.html">
   10장 엔트로피
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  머신러닝 편
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/01.01 데이터 분석의 소개.html">
   1.1 데이터 분석의 소개
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/01.02 머신러닝용 파이썬 패키지.html">
   1.2 머신러닝용 파이썬 패키지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/02.01 데이터 전처리 기초.html">
   2.1 데이터 전처리 기초
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/02.02 범주형 데이터 처리.html">
   2.2 범주형 데이터 처리
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.01.01 NLTK 자연어 처리 패키지.html">
   NLTK 자연어 처리 패키지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.01.02 KoNLPy 한국어 처리 패키지.html">
   KoNLPy 한국어 처리 패키지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.01.03 Scikit-Learn의 문서 전처리 기능.html">
   Scikit-Learn의 문서 전처리 기능
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.01.04 soynlp.html">
   Soynlp 소개
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.01.05 확률론적 언어 모형.html">
   확률론적 언어 모형
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.02.01 이미지 처리 기초.html">
   이미지 처리 기초
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.02.02 이미지 필터링.html">
   이미지 필터링
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.02.03 이미지 컨투어.html">
   이미지 컨투어
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.02.04 이미지 변환.html">
   이미지 변환
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.02.05 이미지 특징 추출.html">
   이미지 특징 추출
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.03.01 사운드 프로세싱 기초.html">
   사운드 프로세싱 기초
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.03.02 푸리에 변환과 스펙트럼.html">
   푸리에 변환과 스펙트럼
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.04.01 지리 정보 데이터 처리.html">
   지리 정보 데이터 처리
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/03.04.02 지오코딩.html">
   Geocoding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/04.01 회귀분석 예제.html">
   4.1 회귀분석 예제
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/04.02 선형회귀분석의 기초.html">
   4.2 선형회귀분석의 기초
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/04.03 스케일링.html">
   4.3 스케일링
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/04.04 범주형 독립변수.html">
   4.4 범주형 독립변수
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/04.05 부분회귀.html">
   4.5 부분회귀
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/05.01 확률론적 선형 회귀모형.html">
   5.1 확률론적 선형 회귀모형
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/05.02 회귀분석의 기하학.html">
   5.2 회귀분석의 기하학
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/05.03 레버리지와 아웃라이어.html">
   5.3 레버리지와 아웃라이어
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/05.04 분산 분석과 모형 성능.html">
   5.4 분산 분석과 모형 성능
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.01 모형 진단과 수정.html">
   6.1 모형 진단과 수정
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.01 모형 진단과 수정.html#id2">
   잔차 정규성
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.01 모형 진단과 수정.html#id3">
   잔차와 독립 변수의 관계
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.01 모형 진단과 수정.html#id4">
   이분산성
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.01 모형 진단과 수정.html#id5">
   자기 상관 계수
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.02 기저함수 모형과 과최적화.html">
   6.2 기저함수 모형과 과최적화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.03 교차검증.html">
   6.3 교차검증
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.04 다중공선성과 변수 선택.html">
   6.4 다중공선성과 변수 선택
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.04 다중공선성과 변수 선택.html#vif">
   VIF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.04 다중공선성과 변수 선택.html#id2">
   보스턴 집값 예측 문제에 응용
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/06.05 정규화 선형회귀.html">
   6.5 정규화 선형회귀
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/07.01 추천 시스템.html">
   13.1 추천 시스템
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.01 분류용 예제 데이터.html">
   5.1 분류용 예제 데이터
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.02 분류용 가상 데이터 생성.html">
   5.2 분류용 가상 데이터 생성
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.02 분류용 가상 데이터 생성.html#make-blobs">
   <code class="docutils literal notranslate">
    <span class="pre">
     make_blobs
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.02 분류용 가상 데이터 생성.html#make-moons">
   <code class="docutils literal notranslate">
    <span class="pre">
     make_moons
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.02 분류용 가상 데이터 생성.html#make-gaussian-quantiles">
   <code class="docutils literal notranslate">
    <span class="pre">
     make_gaussian_quantiles
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.03 분류모형.html">
   5.3 분류모형
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/09.04 분류 성능평가.html">
   5.4 분류 성능평가
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/10.01 로지스틱 회귀분석.html">
   6.1 로지스틱 회귀분석
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/11.01 선형판별분석법과 이차판별분석법.html">
   7.1 선형판별분석법과 이차판별분석법
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/11.02 나이브베이즈 분류모형.html">
   7.2 나이브베이즈 분류모형
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/11.03 감성 분석.html">
   감성 분석
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/12.01 의사결정나무.html">
   8.1 의사결정나무
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/12.02 모형 결합.html">
   12.02 모형 결합
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/12.03 부스팅 방법.html">
   부스팅 방법
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/13.02 서포트 벡터 머신.html">
   서포트 벡터 머신
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/13.03 커널 서포트 벡터 머신.html">
   커널 서포트 벡터 머신
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/14.01 모형 최적화.html">
   모형 최적화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/14.02 비대칭 데이터 문제.html">
   비대칭 데이터 문제
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/14.03 특징 선택.html">
   특징 선택
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/14.04 대규모 데이터 학습.html">
   대규모 데이터 학습
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/16.01 군집화.html">
   군집화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/16.02 K-평균 군집화.html">
   K-평균 군집화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/16.03 디비스캔 군집화.html">
   디비스캔 군집화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/16.04 계층적 군집화.html">
   계층적 군집화
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/16.05 Affinity Propagation.html">
   Affinity Propagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/17.01 그래프 이론 기초.html">
   그래프 이론 기초
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/17.02 그래프 확률모형.html">
   그래프 확률모형
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/17.03 네트워크 추론.html">
   네트워크 추론
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/18.01 가우시안 혼합모형과 EM 방법.html">
   가우시안 혼합모형과 EM 방법
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/18.02 변분법적 추론.html">
   변분법적 추론
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/19.01 몬테카를로 베이지안 분석.html">
   몬테카를로 베이지안 분석
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/19.02 베이지안 회귀 분석 예제.html">
   베이지안 회귀 분석 예제
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03 machine learning/20.01 히든 마코프 모형.html">
   히든 마코프 모형
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/02 mathematics/07.02 기댓값과 확률변수의 변환.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/02 mathematics/07.02 기댓값과 확률변수의 변환.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/executablebooks/jupyter-book/blob/master/02 mathematics/07.02 기댓값과 확률변수의 변환.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   확률변수의 기댓값
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     예제
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     예제
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     연습 문제 7.2.1
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     연습 문제 7.2.2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     예제
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     연습 문제 7.2.3
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   확률변수의 변환
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     연습 문제 7.2.4
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     연습 문제 7.2.5
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   기댓값의 성질
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id13">
   통계량
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   표본평균 확률변수
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     연습 문제 7.2.6
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id16">
   기댓값과 표본평균의 관계
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id17">
   중앙값
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id18">
   최빈값
  </a>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>7.2 기댓값과 확률변수의 변환<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>표본평균, 표본분산 등은 현실세계의 데이터 분포의 모양을 서술하는 특성값이다. 이제부터는 이론적인 확률분포함수의 모양을 서술하는 특성값을 살펴본다. 우선 기댓값부터 공부한다. 기댓값은 표본평균처럼 분포의 위치를 알려주는 특성값이지만 확률분포의 가중합이나 가중적분으로 정의한다.</p>
<div class="section" id="id2">
<h2>확률변수의 기댓값<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>확률변수의 확률밀도함수를 알면 확률변수의 이론적 평균값을 구할 수 있다. 이러한 이론적 평균을 확률변수의 **기댓값(expectation)**이라고 한다. 단순히 평균(mean)이라고 말하기도 한다.</p>
<p>확률변수 <span class="math notranslate nohighlight">\(X\)</span>의 기댓값을 구하는 연산자(operator)는 영어 Expectation의 첫 글자를 사용하여 <span class="math notranslate nohighlight">\(\text{E}[X]\)</span>로 표기한다. 기댓값은 그리스 문자 <span class="math notranslate nohighlight">\(\mu_X\)</span>로 표기한다. 확률변수를 혼동할 염려가 없으면 확률변수 이름은 생략하고 그냥 <span class="math notranslate nohighlight">\(\mu\)</span>라고 써도 된다.</p>
<p><strong>이산확률변수의 기댓값은 표본공간의 원소 <span class="math notranslate nohighlight">\(x_i\)</span>의 가중평균</strong>이다. 이때 가중치는 <span class="math notranslate nohighlight">\(x_i\)</span>가 나올 수 있는 확률 즉 확률질량함수 <span class="math notranslate nohighlight">\(p(x_i)\)</span>이다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
\mu_X = \text{E}[X] = \sum_{x_i \in \Omega} x_ip(x_i) 
\tag{7.2.1}
\end{align}
\]</div>
<div class="section" id="id3">
<h3>예제<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>공정한 주사위에서 나올 수 있는 숫자를 대표하는 확률변수 <span class="math notranslate nohighlight">\(X\)</span>는 나올 수 있는 값이 1, 2, 3, 4, 5, 6 이므로,</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{align}
\begin{aligned}
\mu_X 
&amp;= 1 \cdot p(1) + 2 \cdot p(2) + 3 \cdot p(3) + 4 \cdot p(4) + 5 \cdot p(5) + 6 \cdot p(6) \\
&amp;= 1 \cdot \dfrac{1}{6} + 2 \cdot \dfrac{1}{6} + 3 \cdot \dfrac{1}{6} + 4 \cdot \dfrac{1}{6} + 5 \cdot \dfrac{1}{6} + 6 \cdot \dfrac{1}{6} \\
&amp;= \dfrac{7}{2}
\end{aligned}
\tag{7.2.2}
\end{align}
\end{split}\]</div>
<p>기댓값은 <span class="math notranslate nohighlight">\(\dfrac{7}{2}\)</span>이다.</p>
</div>
<div class="section" id="id4">
<h3>예제<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>공정하지 않은 주사위, 예들 들어 짝수가 나올 확률이 홀수가 나올 확률의 2배인 주사위에서 기댓값을 구하면 다음과 같다.</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{align}
\begin{aligned}
\mu_X 
&amp;= 1 \cdot p(1) + 2 \cdot p(2) + 3 \cdot p(3) + 4 \cdot p(4) + 5 \cdot p(5) + 6 \cdot p(6) \\
&amp;= 1 \cdot \dfrac{1}{9} + 2 \cdot \dfrac{2}{9} + 3 \cdot \dfrac{1}{9} + 4 \cdot \dfrac{2}{9} + 5 \cdot \dfrac{1}{9} + 6 \cdot \dfrac{2}{9} \\
&amp;= \dfrac{11}{3}
\end{aligned}
\tag{7.2.3}
\end{align}
\end{split}\]</div>
<p>기댓값은 <span class="math notranslate nohighlight">\(\dfrac{11}{3}\)</span>이다.</p>
</div>
<div class="section" id="id5">
<h3>연습 문제 7.2.1<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>공정한 동전이 있고 이 동전의 앞면이 나오면 1, 뒷면이 나오면 0인 확률변수 <span class="math notranslate nohighlight">\(X\)</span>가 있다. 이 확률변수의 기댓값 <span class="math notranslate nohighlight">\(\text{E}[X]\)</span>을 구하라.</p>
<p>참고로 데이터 공간에서 기댓값에 대응하는 값인 표본평균을 구하는 공식은 다음과 같았다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
\bar x = \dfrac{1}{N} \sum_{i=1}^N x_i 
\tag{7.2.4}
\end{align}
\]</div>
<p>기댓값 공식과 표본평균 공식에서 <span class="math notranslate nohighlight">\(x_i\)</span>의 의미가 다르다는 점에 유의하라. 기댓값 공식에서 <span class="math notranslate nohighlight">\(x_i\)</span>는 표본공간의 모든 원소를 뜻하지만 표본평균 공식에서 <span class="math notranslate nohighlight">\(x_i\)</span>는 선택된(sampled, realized) 표본만을 뜻한다.</p>
</div>
<div class="section" id="id6">
<h3>연습 문제 7.2.2<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>기댓값을 구하는 공식에서는 확률을 가중치로 곱한다. 그런데 왜 표본평균을 구하는 공식에서는 확률 가중치가 없는가?</p>
<p><strong>연속확률변수의 기댓값은 확률밀도함수 <span class="math notranslate nohighlight">\(p(x)\)</span>를 가중치로 하여 모든 가능한 표본 <span class="math notranslate nohighlight">\(x\)</span>를 적분</strong>한 값이다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
\mu_X = \text{E}[X] = \int_{-\infty}^{\infty} x p(x) dx 
\tag{7.2.5}
\end{align}
\]</div>
<img src="https://datascienceschool.net/upfiles/5faa8355cc1847d19cf03aca65fe4b79.png" width="100%;"><p>그림 7.2.1 : 기댓값 계산</p>
<p><strong>기댓값은</strong> 여러 가능한 <span class="math notranslate nohighlight">\(x\)</span>값을 확률(또는 확률밀도)값에 따라 가중합을 한 것이므로 가장 확률(또는 확률밀도)이 높은 <span class="math notranslate nohighlight">\(x\)</span>값 근처의 값이 된다. 즉, <strong>확률(또는 확률밀도)가 모여 있는 곳의 위치</strong>를 나타낸다.</p>
</div>
<div class="section" id="id7">
<h3>예제<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>회전하는 원반을 이용하여 복권 번호를 결정하는 문제에서 확률밀도함수 <span class="math notranslate nohighlight">\(p(x)\)</span>와 여기에서 <span class="math notranslate nohighlight">\(x\)</span>가 곱해진 함수 <span class="math notranslate nohighlight">\(xp(x)\)</span>의 모양은 다음과 같다. 기댓값은 이 함수 <span class="math notranslate nohighlight">\(xp(x)\)</span>를 적분하여 구한 삼각형처럼 생긴 함수의 면적이다.</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
E[X] = xp(x)\text{의 면적} = \dfrac{1}{2} \cdot 360 \cdot 1 = 180
\tag{7.2.6}
\end{align}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">p</span><span class="p">[(</span><span class="mi">0</span> <span class="o">&lt;</span> <span class="n">x</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">360</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">360</span>
<span class="n">xp</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">p</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">360</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;$p(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$ (도)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">360</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;$xp(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$ (도)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/07.02 기댓값과 확률변수의 변환_14_0.png" src="../_images/07.02 기댓값과 확률변수의 변환_14_0.png" />
</div>
</div>
<p>만약 0도에서 180도 사이에 화살이 2배 더 잘 박히도록 원반이 조작되었다면 확률밀도함수 <span class="math notranslate nohighlight">\(p(x)\)</span>와 여기에서 <span class="math notranslate nohighlight">\(x\)</span>가 곱해진 함수 <span class="math notranslate nohighlight">\(xp(x)\)</span> 모양은 다음과 같다. 기댓값은 이 함수 <span class="math notranslate nohighlight">\(xp(x)\)</span>를 적분하여 구한 함수의 면적이다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">p</span><span class="p">[(</span><span class="mi">0</span> <span class="o">&lt;</span> <span class="n">x</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">180</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">360</span><span class="p">)</span>
<span class="n">p</span><span class="p">[(</span><span class="mi">180</span> <span class="o">&lt;</span> <span class="n">x</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">360</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">360</span><span class="p">)</span>
<span class="n">xp</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">p</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">360</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;$p(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$ (도)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xp</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">360</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;$xp(x)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$ (도)&quot;</span><span class="p">)</span>\

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/07.02 기댓값과 확률변수의 변환_16_0.png" src="../_images/07.02 기댓값과 확률변수의 변환_16_0.png" />
</div>
</div>
</div>
<div class="section" id="id8">
<h3>연습 문제 7.2.3<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>확률변수 <span class="math notranslate nohighlight">\(Y\)</span>는 0도에서 180도 사이에 화살이 2배 더 잘 박히도록 조작된 원반을 이용하여 복권 번호를 결정하는 문제에서 나오는 각도다. 확률변수 <span class="math notranslate nohighlight">\(Y\)</span>의 기댓값 <span class="math notranslate nohighlight">\(\text{E}[Y]\)</span>를 구하라.</p>
</div>
</div>
<div class="section" id="id9">
<h2>확률변수의 변환<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>우리가 얻은 데이터의 값을 어떤 함수 <span class="math notranslate nohighlight">\(f\)</span>에 넣어서 변화시킨다고 가정하자. 그러면 새로운 데이터 집합이 생긴다.</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\{ x_1, x_2, \ldots, x_N \} \rightarrow \{ f(x_1), f(x_2), \ldots, f(x_N) \}
\tag{7.2.7}
\end{align}
\]</div>
<p>이 새로운 데이터를 <span class="math notranslate nohighlight">\(\{y_i\}\)</span>라고 부르자. <span class="math notranslate nohighlight">\(\{y_i\}\)</span>는 기존의 데이터와 다른 새로운 데이터이므로 다른 확률변수라고 볼 수 있다. 예를 들어 데이터 <span class="math notranslate nohighlight">\(\{x_i\}\)</span>를 만드는 확률변수가 <span class="math notranslate nohighlight">\(X\)</span>라면 데이터 <span class="math notranslate nohighlight">\(\{y_i\}\)</span>를 만드는 데이터는 <span class="math notranslate nohighlight">\(Y\)</span>라는 새로운 확률변수가 된다.</p>
<p>이렇게 **기존의 확률변수를 사용하여 새로운 확률변수를 만드는 것을 확률변수의 변환(transform)**이라고 한다. 함수 <span class="math notranslate nohighlight">\(f\)</span>를 사용해  확률변수를 변환할 때는 다음처럼 표기한다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
Y = f(X) 
\tag{7.2.8}
\end{align}
\]</div>
<p>확률 변수의 변환은 여러 확률변수가 있을 때도 성립한다. 예를 들어 두 확률변수 <span class="math notranslate nohighlight">\(X\)</span>와 <span class="math notranslate nohighlight">\(Y\)</span>가 있다고 가정하였을 때, 새로운 확률변수 <span class="math notranslate nohighlight">\(Z = X + Y\)</span>는 확률변수 <span class="math notranslate nohighlight">\(X\)</span>에서 나온 값과 확률변수 <span class="math notranslate nohighlight">\(Y\)</span>에서 나온 값을 더한 값이 나오도록 하는 확률변수를 뜻한다.</p>
<img src="https://datascienceschool.net/upfiles/163b381a40e44a50b372428bc02d0cfc.png" width="100%;"><p>그림 7.2.2 : 확률변수의 변환</p>
<div class="section" id="id10">
<h3>연습 문제 7.2.4<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>확률변수 <span class="math notranslate nohighlight">\(X\)</span>는 주사위를 던져 나오는 수를 나타내는 확률변수다. 그리고  <span class="math notranslate nohighlight">\(Y\)</span>는 주사위를 던져나오는 수에 2배를 한 수를 나타내는 확률변수다. <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>의 확률질량함수의 그래프를 각각 그려라.</p>
<p>확률변수 <span class="math notranslate nohighlight">\(X\)</span>에서 표본을 <span class="math notranslate nohighlight">\(N\)</span>번 뽑아서 그 값을 더하는 경우에는 다음처럼 원래 확률변수의 복사본 <span class="math notranslate nohighlight">\(X_1, X_2, \ldots, X_N\)</span>을 만든 다음 이 복사본 확률변수의 표본값을 더한 형태로 변환식을 써야 한다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
Y = X_1 + X_2 + \cdots X_N 
\tag{7.2.9}
\end{align}
\]</div>
<p>이렇게 복사본을 만들어 첨자를 붙이는 이유는 <span class="math notranslate nohighlight">\(X_1\)</span>과 <span class="math notranslate nohighlight">\(X_2\)</span>가 같은 확률분포를 가지는 확률변수이지만 표본값이 다르기 때문이다. 만약 다음과 같이 쓰면,</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
Y = X + X + \cdots X
\tag{7.2.10}
\end{align}
\]</div>
<p>이 식은 다음처럼 전혀 다른 확률변수를 가리킨다.</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
Y = N \cdot X
\tag{7.2.11}
\end{align}
\]</div>
</div>
<div class="section" id="id11">
<h3>연습 문제 7.2.5<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>확률변수 <span class="math notranslate nohighlight">\(X_1\)</span>과 <span class="math notranslate nohighlight">\(X_2\)</span>는 각각 주사위를 던져 나오는 수를 나타내는 확률변수다. 그리고  <span class="math notranslate nohighlight">\(Y\)</span>는 두 주사위를 동시에 던져 나오는 수의 합을 나타내는 확률변수다. 확률변수 <span class="math notranslate nohighlight">\(X_1\)</span>, <span class="math notranslate nohighlight">\(X_2\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>의 확률질량함수의 그래프를 각각 그려라.</p>
</div>
</div>
<div class="section" id="id12">
<h2>기댓값의 성질<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>기댓값은 다음과 같은 성질을 가진다는 것을 수학적으로 증명할 수 있다. 변환된 확률변수의 기댓값을 계산할 때는 기댓값의 성질을 이용한다.</p>
<ul class="simple">
<li><p>확률변수가 아닌 상수 <span class="math notranslate nohighlight">\(c\)</span>에 대해</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\begin{align}
\text{E}[c] = c
\tag{7.2.12}
\end{align}
\]</div>
<ul class="simple">
<li><p>선형성</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\begin{align}
\text{E}[cX] = c \text{E}[X]
\tag{7.2.13}
\end{align}
\]</div>
<div class="math notranslate nohighlight">
\[
\begin{align}
\text{E}[X + Y] = \text{E}[X] + \text{E}[Y]
\tag{7.2.14}
\end{align}
\]</div>
<div class="math notranslate nohighlight">
\[
\begin{align}
\text{E}[c_1X + c_2Y] = c_1\text{E}[X] + c_2\text{E}[Y] 
\tag{7.2.15}
\end{align}
\]</div>
</div>
<div class="section" id="id13">
<h2>통계량<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p>확률변수 <span class="math notranslate nohighlight">\(X\)</span>로부터 데이터 집합 <span class="math notranslate nohighlight">\(\{ x_1, x_2, \ldots, x_N \}\)</span>을 얻었다고 하자. 이 **데이터 집합의 모든 값을 정해진 어떤 공식에 넣어서 하나의 숫자를 구한 것을 통계량(statistics)**이라고 한다. 예를 들어 표본의 합, 표본평균, 표본중앙값, 표본분산 등은 모두 통계량이다. 통계량도 확률변수의 변환에 포함된다.</p>
<img src="https://datascienceschool.net/upfiles/27ae3dd69e0e4ba1b2844a7659ad601c.png" width="100%;"><p>그림 7.2.3 : 통계량</p>
</div>
<div class="section" id="id14">
<h2>표본평균 확률변수<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>확률변수로부터 <span class="math notranslate nohighlight">\(N\)</span>개의 표본을 만들어 이 표본집합의 표본평균을 구하면 이렇게 구한 표본평균 값도 확률변수가 된다. 표본평균 확률변수는 원래의 확률변수 이름에 윗줄(bar)을 추가하여 <span class="math notranslate nohighlight">\(\bar{X}\)</span>와 같이 표기한다. 예를 들어 확률변수 <span class="math notranslate nohighlight">\(X\)</span>에서 나온 표본으로 만들어진 표본평균 확률변수는 <span class="math notranslate nohighlight">\(\bar{X}\)</span>로 표기한다.</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\bar{X} = \dfrac{1}{N}\sum_{i=1}^{N} X_i
\tag{7.2.16}
\end{align}
\]</div>
<p>위 식에서  <span class="math notranslate nohighlight">\(X_i\)</span>는 <span class="math notranslate nohighlight">\(i\)</span>번째로 실현된 표본값을 생성하는 확률변수를 의미한다. 이 확률변수 <span class="math notranslate nohighlight">\(X_i\)</span>는 원래의 확률변수 <span class="math notranslate nohighlight">\(X\)</span>의 복사본이다.</p>
<img src="https://datascienceschool.net/upfiles/f3f08cc5af084475bafa7ae2a1c35b5e.png" width="100%;"><p>그림 7.2.4 : 표본평균 확률변수</p>
<div class="section" id="id15">
<h3>연습 문제 7.2.6<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>표본평균 <span class="math notranslate nohighlight">\(\bar{x}\)</span>의 값은 확률적인 데이터이고 이를 생성하는 확률변수 <span class="math notranslate nohighlight">\(\bar{X}\)</span>는 위와 같이 정의할 수 있었다. 그렇다면 (편향)표본분산 <span class="math notranslate nohighlight">\(s^2\)</span>의 값은 확률적인 데이터인가? 만약 그렇다면 이를 생성하는 확률변수 <span class="math notranslate nohighlight">\(S^2\)</span>은 어떻게 정의해야 하는가?</p>
</div>
</div>
<div class="section" id="id16">
<h2>기댓값과 표본평균의 관계<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h2>
<p>표본평균도 확률변수이므로 기댓값이 존재한다. 표본평균의 기댓값은 원래의 확률변수의 기댓값과 같다는 것을 다음처럼 증명할 수 있다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
\text{E}[ \bar{X} ] = \text{E}[X] 
\tag{7.2.17}
\end{align}
\]</div>
<p>(증명)</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{align}
\begin{aligned}
\text{E}[\bar{X}] 
&amp;= \text{E}\left[\dfrac{1}{N}\sum_{i=1}^{N}X_i \right]  \\
&amp;= \dfrac{1}{N}\sum_{i=1}^{N}\text{E}[X_i]  \\
&amp;= \dfrac{1}{N}\sum_{i=1}^{N}\text{E}[X] \\
&amp;= \dfrac{1}{N} N \text{E}[X] \\ 
&amp;= \text{E}[X]  \\
\end{aligned}
\tag{7.2.18}
\end{align}
\end{split}\]</div>
<p>이 식이 뜻하는 바는 다음과 같다.</p>
<blockquote>
<div><p>표본평균은 확률변수의 기댓값 근처의 값이 된다.</p>
</div></blockquote>
<p>예를 들어 공정한 주사위의 기댓값은 3.5이다. 이 주사위를 던져 나온 값의 평균 즉 표본평균은 3.62346 또는 3.40987처럼 항상 3.5 근처의 값이 나오게 된다.</p>
</div>
<div class="section" id="id17">
<h2>중앙값<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<p><strong>확률변수의 중앙값(median)은 중앙값보다 큰 값이 나올 확률과 작은 값이 나올 확률이 0.5로 같은 값</strong>을 뜻한다. 따라서 다음과 같이 누적확률분포 <span class="math notranslate nohighlight">\(F(x)\)</span>에서 중앙값을 계산할 수 있다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
0.5 = F(\text{중앙값}) 
\tag{7.2.19}
\end{align}
\]</div>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
\text{중앙값} = F^{-1}(0.5) 
\tag{7.2.20}
\end{align}
\]</div>
<img src="https://datascienceschool.net/upfiles/178249d00ab7433bb3d75ed50f4d939c.png" width="100%;"><p>그림 7.2.5 : 중앙값</p>
</div>
<div class="section" id="id18">
<h2>최빈값<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h2>
<p>**이산확률분포에서는 가장 확률 값이 큰 수를 최빈값(most frequent value)**이라고 한다. 하지만 연속확률분포인 경우에는 어느 값에 대해서나 특정한 값이 나올 확률은 0(zero)이므로 <strong>연속확률분포의 최빈값(mode)은 확률밀도함수 <span class="math notranslate nohighlight">\(p(x)\)</span>의 값이 가장 큰 확률변수의 값</strong>으로 정의한다. 즉 확률밀도함수의 최댓값의 위치다.</p>
<div class="math notranslate nohighlight">
\[ 
\begin{align}
\text{최빈값} = \arg \max_x p(x) 
\tag{7.2.21}
\end{align}
\]</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./02 mathematics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="07.01 확률적 데이터와 확률변수.html" title="previous page">7.1 확률적 데이터와 확률변수</a>
    <a class='right-next' id="next-link" href="07.03 분산과 표준편차.html" title="next page">7.3 분산과 표준편차</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By 김도형<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>